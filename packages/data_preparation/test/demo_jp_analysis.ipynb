{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing Point cloud data extraction and token attribution (Circum tutorial) for the point cloud dataset of noto region of Japan.\n",
    "\n",
    "This are tutorials for analysing the pointcloud dataset released by the geospatial organisation of Japan for the region of Noto Peninsula before the earthquake.\n",
    "\n",
    "This will demonstrate our E2E pipeline for the users providing how they can\n",
    "- Parse the various tiles from the dataset and get the initial metadata of the pointcloud.\n",
    "- Perform the preprocessing steps to get the pointcloud in a format that can be used for further steps processing.\n",
    "- After cropping and generating the new lidar file for doing the tiling process (optional).\n",
    "- And finally attributing the tokens in for data providers for their contribution to the protocol.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing all the requisite dependencies of the data_preparation project.\n",
    "%pip install  -r ../requirements.txt\n",
    "## installing the dependencies of the protocol.\n",
    "!pip install flytekit bacalhau-sdk flytekitplugins-bacalhau \n",
    "\n",
    "## for storage clients, we provide the intigeration with IPFS storage using lighthouse or the web3.storage\n",
    "!pip install lighthouseweb3\n",
    "\n",
    "## for the web3 storage:\n",
    "!npm install -g @web3-storage/w3-cli \n",
    "## then storing the necessary env variables to the bashrc in order to run the w3cli without the need of creating alias.\n",
    "#!cat WEB3_STORAGE_ENV >> ~/.bashrc\n",
    "!w3 space create circum_user_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in getting values for file 07ED5834.las: buffer size must be a multiple of element size\n",
      "error in getting values for file japan_ne.zip: Invalid file signature \"b'PK\\x03\\x04'\"\n",
      "error in getting values for file bunny.pcd: Invalid file signature \"b'# .P'\"\n",
      "        filename                                         dimensions  \\\n",
      "0   07ED4942.las  (-0.01, -1000.0, 166499.99, 165750.0, 242.1400...   \n",
      "1   07ED5814.las  (-6000.01, -7000.0, 164249.99, 163500.0, 197.6...   \n",
      "2   07ED4933.las  (-3000.01, -4000.0, 165749.99, 165000.0, 183.0...   \n",
      "3   07ED5821.las  (-5000.01, -6000.0, 164999.99, 164250.0, 123.2...   \n",
      "4   07ED4844.las  (-4000.01, -5000.0, 165749.99, 165000.0, 91.42...   \n",
      "5   07ED5824.las  (-4000.01, -5000.0, 164249.99, 163500.0, 329.9...   \n",
      "6   07ED5822.las  (-4000.01, -5000.0, 164999.99, 164250.0, 254.1...   \n",
      "7   07ED4934.las  (-2000.01, -3000.0, 165749.99, 165000.0, 274.5...   \n",
      "8   07ED5832.las  (-6000.01, -7000.0, 163499.99, 162750.0, 262.3...   \n",
      "9   07ED5831.las  (-7000.01, -8000.0, 163499.99, 162750.0, 49.96...   \n",
      "10  07ED5823.las  (-5000.01, -6000.0, 164249.99, 163500.0, 246.3...   \n",
      "11  07ED5833.las  (-7000.01, -8000.0, 162749.99, 162000.0, 261.5...   \n",
      "12  07ED4943.las  (-1000.01, -2000.0, 165749.99, 165000.0, 273.8...   \n",
      "13  07ED4932.las  (-2000.01, -3000.0, 166499.99, 165750.0, 185.1...   \n",
      "14  07ED4944.las  (-0.01, -1000.0, 165749.99, 165000.0, 249.86, ...   \n",
      "15  07ED4941.las  (-1000.01, -2000.0, 166499.99, 165750.0, 221.3...   \n",
      "16  07ED4924.las  (-0.01, -1000.0, 167249.99, 166500.0, 109.73, ...   \n",
      "\n",
      "   point_amount                                          maxs_mins  scale  \\\n",
      "0      18136802  ([-1.0000000e-02  1.6649999e+05  2.4214000e+02...  0.001   \n",
      "1       6359273  ([ -6000.01 164249.99    197.64], [-7.000e+03 ...  0.001   \n",
      "2      15392307  ([ -3000.01 165749.99    183.07], [-4.00e+03  ...   0.01   \n",
      "3       3327400  ([-5.0000100e+03  1.6499999e+05  1.2324000e+02...  0.001   \n",
      "4       2535148  ([-4.0000100e+03  1.6574999e+05  9.1420000e+01...   0.01   \n",
      "5      22866700  ([ -4000.01 164249.99    329.97], [-5.000e+03 ...   0.01   \n",
      "6      17083712  ([ -4000.01 164999.99    254.14], [ -5000. 164...   0.01   \n",
      "7      22308909  ([ -2000.01 165749.99    274.59], [-3.00e+03  ...  0.001   \n",
      "8      14595005  ([ -6000.01 163499.99    262.33], [-7.0000e+03...  0.001   \n",
      "9       1096053  ([-7.0000100e+03  1.6349999e+05  4.9960000e+01...  0.001   \n",
      "10     17169376  ([ -5000.01 164249.99    246.34], [-6.000e+03 ...  0.001   \n",
      "11      9275743  ([ -7000.01 162749.99    261.53], [-8.00e+03  ...  0.001   \n",
      "12     19711367  ([ -1000.01 165749.99    273.87], [-2.000e+03 ...  0.001   \n",
      "13      6038623  ([ -2000.01 166499.99    185.16], [-3.0000e+03...  0.001   \n",
      "14     17864031  ([-1.0000000e-02  1.6574999e+05  2.4986000e+02...  0.001   \n",
      "15     12582210  ([ -1000.01 166499.99    221.35], [-2.0000e+03...  0.001   \n",
      "16      2783359  ([-1.0000000e-02  1.6724999e+05  1.0973000e+02...  0.001   \n",
      "\n",
      "                                     point_dimensions  \n",
      "0   [(X, DimensionKind.SignedInteger, 32, 1, True,...  \n",
      "1   [(X, DimensionKind.SignedInteger, 32, 1, True,...  \n",
      "2   [(X, DimensionKind.SignedInteger, 32, 1, True,...  \n",
      "3   [(X, DimensionKind.SignedInteger, 32, 1, True,...  \n",
      "4   [(X, DimensionKind.SignedInteger, 32, 1, True,...  \n",
      "5   [(X, DimensionKind.SignedInteger, 32, 1, True,...  \n",
      "6   [(X, DimensionKind.SignedInteger, 32, 1, True,...  \n",
      "7   [(X, DimensionKind.SignedInteger, 32, 1, True,...  \n",
      "8   [(X, DimensionKind.SignedInteger, 32, 1, True,...  \n",
      "9   [(X, DimensionKind.SignedInteger, 32, 1, True,...  \n",
      "10  [(X, DimensionKind.SignedInteger, 32, 1, True,...  \n",
      "11  [(X, DimensionKind.SignedInteger, 32, 1, True,...  \n",
      "12  [(X, DimensionKind.SignedInteger, 32, 1, True,...  \n",
      "13  [(X, DimensionKind.SignedInteger, 32, 1, True,...  \n",
      "14  [(X, DimensionKind.SignedInteger, 32, 1, True,...  \n",
      "15  [(X, DimensionKind.SignedInteger, 32, 1, True,...  \n",
      "16  [(X, DimensionKind.SignedInteger, 32, 1, True,...  \n"
     ]
    }
   ],
   "source": [
    "import laspy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from subprocess import call\n",
    "params_list = []\n",
    "\n",
    "## downloading the \n",
    "\n",
    "def read_data_header(base_dir = '../datas/'):\n",
    "    ## downloading the dataset\n",
    "    if not os.path.exists(base_dir):\n",
    "        call([\"wget\", \"https://gic-ishikawa.s3.ap-northeast-1.amazonaws.com/2024/noto/las/notoeast1.zip\", \"-O\", \"japan_ne.zip\"])\n",
    "        call([\"7z\",  \"-x\" , \"japan_ne.zip\"])\n",
    "        call([\"rm\", \"japan_ne.zip\"])\n",
    "    \n",
    "    for it in os.listdir(base_dir):\n",
    "        try:\n",
    "            file_path = os.path.join(base_dir, it)\n",
    "            read_file = laspy.read(file_path)\n",
    "            dimensions = (str(read_file.header.x_max), str(read_file.header.x_min) ,str(read_file.header.y_max) ,str(read_file.header.y_min), str(read_file.header.z_max) ,str(read_file.header.z_min) )\n",
    "            point_amount = (str(read_file.header.point_count))\n",
    "            maxs_mins = (str(read_file.header.maxs), str(read_file.header.mins))\n",
    "            scale = (str(read_file.header.scale[0]))\n",
    "            point_dimensions = (read_file.point_format.dimensions)  \n",
    "            #user_data = read_file['user_data']          \n",
    "            \n",
    "            params_list.append({\n",
    "            \"filename\": it,\n",
    "            \"dimensions\": dimensions,\n",
    "            \"point_amount\": point_amount,\n",
    "            \"maxs_mins\": maxs_mins,\n",
    "            \"scale\": scale,\n",
    "            \"point_dimensions\": point_dimensions,\n",
    "            })    \n",
    "            \n",
    "            # print('dimensions' + ' ' + str(read_file.header.x_max) + ' ' + str(read_file.header.x_min) + ' ' + str(read_file.header.y_max) + ' ' + str(read_file.header.y_min))\n",
    "            # print('number of points' + ' ' + str(read_file.header.point_count))\n",
    "            # print('header maxs and mins ' + '...' + str(read_file.header.maxs) + '...' + str(read_file.header.mins))\n",
    "            # print('scale:' + str(read_file.header.scale[0]))\n",
    "            # print('offset:' + str(read_file.header.offset[0]))\n",
    "            # print('crs code:' + str(read_file))\n",
    "            # print ('dimensions:' + str(read_file.point_format.dimensions))\n",
    "        except Exception as e:\n",
    "            print( f\"error in getting values for file {it}: \" +str(e))\n",
    "    df = pd.DataFrame(params_list)\n",
    "    return df\n",
    "    \n",
    "print(read_data_header())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file details: major-version: 1\n",
      "-----------------------------------------------------\n",
      "scaling values:  (0.01, 0.01, 0.01)\n",
      "example of scaling of the coordinates: ((0.35447227,), (1.36756165,), (1.0,))\n"
     ]
    }
   ],
   "source": [
    "## functions for operating on las file.\n",
    " \n",
    "def parameters_header(lidar_file_path = \"../datas/07ED4844.las\"):\n",
    "    \"\"\"\n",
    "    This function reads the las file header and returns the parameters as a dictionary\n",
    "    \"\"\"\n",
    "    params = []\n",
    "    with laspy.open(lidar_file_path) as fh:\n",
    "        print(f\"file details: major-version: {fh.header.major_version}\")\n",
    "        params = {\n",
    "            \n",
    "                \"x_min\" : fh.header.x_min,\n",
    "                \"x_max\" : fh.header.x_max,\n",
    "                \"x_scale\" : fh.header.x_scale,\n",
    "                \"x_offset\" : fh.header.x_offset,\n",
    "                \"y_min\" : fh.header.y_min,\n",
    "                \"y_max\" : fh.header.y_max,\n",
    "                \"y_scale\" : fh.header.y_scale,\n",
    "                \"y_offset\" : fh.header.y_offset,\n",
    "                \"z_min\" : fh.header.z_min,\n",
    "                \"z_max\" : fh.header.z_max,\n",
    "                \"z_scale\" : fh.header.z_scale,\n",
    "                \"z_offset\" : fh.header.z_offset,\n",
    "            }\n",
    "        \n",
    "        return pd.DataFrame(params, index=[0])\n",
    "\n",
    "df_init = parameters_header()\n",
    "\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(f\"scaling values:  {df_init['x_scale'][0], df_init['y_scale'][0], df_init['z_scale'][0]}\")\n",
    "def scaling_parameters(x,y,z, df_init):\n",
    "    \"\"\"\n",
    "    fetches all the sides of the X,Y,Z axis and returns them as a dictionary\n",
    "    \"\"\"    \n",
    "     \n",
    "    #if (x + df_init['x_scale'][0]) > df_init['']     \n",
    "    X_coord = (x * df_init['x_scale'][0]) + df_init['x_offset'][0],\n",
    "    Z_coord = (z * df_init[\"z_scale\"][0]) + df_init[\"z_offset\"][0],\n",
    "    Y_coord= (y * df_init[\"y_scale\"][0]) + df_init[\"y_offset\"][0],\n",
    "    return X_coord,Y_coord,Z_coord\n",
    "\n",
    "\n",
    "def determine_correct_indices(lidar_file_path):\n",
    "    \"\"\"\n",
    "    defines the indices that are not valid for the point cloud.\n",
    "    \"\"\"\n",
    "    with laspy.open(lidar_file_path) as read_file:\n",
    "        ## define the current in-valid values for the parameters:\n",
    "        X_invalid = (read_file.header.mins[0] > abs(df_init['x_max'][0])) | (read_file.header.maxs[0] < df_init['x_min'][0])\n",
    "        Y_invalid = (read_file.header.mins[1] > abs(df_init['y_max'][0])) | (read_file.header.maxs[1] < df_init['y_min'][0])\n",
    "        Z_invalid = (read_file.header.mins[2] > abs(df_init['z_max'][0])) | (read_file.header.maxs[2] < df_init['z_min'][0])\n",
    "        bad_indices = np.where(X_invalid | Y_invalid | Z_invalid)\n",
    "\n",
    "    print(bad_indices)\n",
    "\n",
    "\n",
    "print(\"example of scaling of the coordinates: \" + str(scaling_parameters(35.447227, 136.756165,100, df_init)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now running the cropping step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PDAL_template_manual' from 'data_preparation.llm.pipeline_generation' (/home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/data_preparation/test/../../data_preparation/llm/pipeline_generation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GeoDataFrame, points_from_xy\n\u001b[1;32m      7\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../../\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_preparation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline_generation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m  PDAL_template_manual\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msubprocess\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m  check_call\n\u001b[1;32m     11\u001b[0m Points1 \u001b[38;5;241m=\u001b[39m Point(\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;241m37.124\u001b[39m), \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;241m136.54\u001b[39m), \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;241m1.0\u001b[39m))\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'PDAL_template_manual' from 'data_preparation.llm.pipeline_generation' (/home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/data_preparation/test/../../data_preparation/llm/pipeline_generation.py)"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point  \n",
    "from pyproj import Transformer\n",
    "import sys\n",
    "from geopandas import GeoDataFrame, points_from_xy\n",
    "sys.path.append(\"../../../\")\n",
    "from data_preparation.llm.pipeline_generation import  PDAL_template_manual\n",
    "from subprocess import  check_call\n",
    "\n",
    "Points1 = Point(float(37.124), float(136.54), float(1.0))\n",
    "Points2 = Point(float(38.124), float(137.54), float(1.0))\n",
    "transformer = Transformer.from_crs('EPSG:4326','EPSG:6685') ## for GPS coordiantes to japan coordinates\n",
    "lidar_file_path = \"../datas/07ED4844.las\"\n",
    "\n",
    "## taking exampl of the points that are considered as boundation points \n",
    "X1,Y1,Z1 = transformer.transform(Points1.x, Points1.y, Points1.z)\n",
    "X2,Y2,Z2 = transformer.transform(Points2.x, Points2.y, Points2.z)\n",
    "\n",
    "## scaling to thelocal coordinates\n",
    "X1_scaled, Y1_scaled, Z1_scaled = scaling_parameters(X1,Y1,Z1,df_init)\n",
    "X2_scaled, Y2_scaled, Z2_scaled = scaling_parameters(X2,Y2,Z2,df_init)\n",
    "\n",
    "\n",
    "buffer_radius = 0.3\n",
    "\n",
    "print(f\"finally scaled params: X_Scaled: {X1_scaled} to {X2_scaled}, Y_scaled:  {Y1_scaled} to {Y2_scaled} , Z_scaled: {Z1_scaled} to {Z2_scaled} \")\n",
    "print(\"so now applying the cropping technique  using PDAL\")\n",
    "fileInfo = laspy.read(lidar_file_path)\n",
    "\n",
    "\n",
    "# async def pdal_pipeline_processing(filepath, point_x, point_y, point_z, buffer_radius, final_laz_file):\n",
    "#     try:\n",
    "#         open_ai = PDAL_json_generation_template()\n",
    "#         open_ai.define_assistant_parameter(\"pdal_generator\", \"transform_cropping.json\")\n",
    "#         await open_ai.creating_message_thread(f\"i want you to create a json file (named transform_cropping.json) that converts the given laz file stored in {filepath} by cropping the section with center as {Point(point_x,point_y,point_z)} and radius of {buffer_radius}, having the final transformed filename as {final_laz_file}\")\n",
    "#         print(\"the application is finally generated: \" + os.path.join('.', \"transform_cropping.json\"))\n",
    "#         assert os.path.isfile(\"transform_cropping.json\") is True\n",
    "#         check_call([\"pdal\", \"pipeline\", \"transform_cropping.json\"])\n",
    "#         assert os.path.isfile(\"cropped.laz\") is True\n",
    "#     except Exception as e:\n",
    "#         print(\"under the pdal_pipeline_processing, the following error:  \" + str(e))\n",
    "    \n",
    "\n",
    "def generate_crop_pipeline():\n",
    "    manual_template = PDAL_template_manual()\n",
    "    lidar_file_path = \"../datas/07ED4844.las\"\n",
    "    points = \"POINT({}{}{})\".format(X1_scaled,Y1_scaled,Z1_scaled)\n",
    "    manual_template.generate_cropping_template(lidar_file_path,points,10,\"demo_crop.json\")\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #await pdal_pipeline_processing(lidar_file_path, X1_scaled, Y1_scaled, Z1_scaled, buffer_radius, \"cropped.laz\")\n",
    "    generate_crop_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now comes the reconstruction step(optional) : \n",
    "\n",
    "In the gepspatial pipeline, we rarely get a well defined pointcloud from the start. thus the pointcloud needs to be reconstructed using the reconstruction algorithms. below we will be giving an example of the how we run the decentralised compute over data platform in order to schedule the reconstruction of the pointcloud. this process at this instance will be simulated on the top of bacalhau public network where the nodes are managed on no cost by the parent company expanso, but in the circum protocol we will be providing the custom network of nodes based on the requirements of the user regarding the nodes, they will be able too bid for the compute job along with the description of the  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing BacalhauTask with name: running surface_reconstruction_job\n",
      "executing BacalhauTask with name: store_ipfs_result\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Dataclass <class '__main__.reconstructionDatasetFile'> should be decorated with @dataclass_json to be serialized correctly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 33\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;241m=\u001b[39m filename\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscene_type \u001b[38;5;241m=\u001b[39m scene_type\n\u001b[1;32m     32\u001b[0m \u001b[38;5;129;43m@task\u001b[39;49m\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43msurface_reconstruction_job\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_params_job\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreconstructionDatasetFile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask_1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbacalhau_reconstruction_job\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m            \u001b[49m\u001b[43mapi_version\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mv0.1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspec\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mSpec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m   \u001b[49m\n",
      "File \u001b[0;32m~/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages/flytekit/core/task.py:280\u001b[0m, in \u001b[0;36mtask\u001b[0;34m(_task_function, task_config, cache, cache_serialize, cache_version, retries, interruptible, deprecated, timeout, container_image, environment, requests, limits, secret_requests, execution_mode, task_resolver, docs, disable_deck, pod_template, pod_template_name)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m task_instance\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _task_function:\n\u001b[0;32m--> 280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_task_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages/flytekit/core/task.py:260\u001b[0m, in \u001b[0;36mtask.<locals>.wrapper\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(fn: Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PythonFunctionTask[T]:\n\u001b[1;32m    250\u001b[0m     _metadata \u001b[38;5;241m=\u001b[39m TaskMetadata(\n\u001b[1;32m    251\u001b[0m         cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[1;32m    252\u001b[0m         cache_serialize\u001b[38;5;241m=\u001b[39mcache_serialize,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    257\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    258\u001b[0m     )\n\u001b[0;32m--> 260\u001b[0m     task_instance \u001b[38;5;241m=\u001b[39m \u001b[43mTaskPlugins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_pythontask_plugin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtask_config\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontainer_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontainer_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequests\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequests\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43msecret_requests\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msecret_requests\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask_resolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_resolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable_deck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_deck\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpod_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpod_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpod_template_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpod_template_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m     update_wrapper(task_instance, fn)\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m task_instance\n",
      "File \u001b[0;32m~/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages/flytekit/core/tracker.py:35\u001b[0m, in \u001b[0;36mInstanceTrackingMeta.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 35\u001b[0m     o \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mInstanceTrackingMeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     o\u001b[38;5;241m.\u001b[39m_instantiated_in \u001b[38;5;241m=\u001b[39m InstanceTrackingMeta\u001b[38;5;241m.\u001b[39m_find_instance_module()\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m o\n",
      "File \u001b[0;32m~/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages/flytekit/core/python_function_task.py:121\u001b[0m, in \u001b[0;36mPythonFunctionTask.__init__\u001b[0;34m(self, task_config, task_function, task_type, ignore_input_vars, execution_mode, task_resolver, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m mutated_interface \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_native_interface\u001b[38;5;241m.\u001b[39mremove_inputs(ignore_input_vars)\n\u001b[1;32m    120\u001b[0m name, _, _, _ \u001b[38;5;241m=\u001b[39m extract_task_module(task_function)\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmutated_interface\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask_resolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_resolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_resolver \u001b[38;5;129;01mis\u001b[39;00m default_task_resolver:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# The default task resolver can't handle nested functions\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# TODO: Consider moving this to a can_handle function or something inside the resolver itself.\u001b[39;00m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m istestfunction(func\u001b[38;5;241m=\u001b[39mtask_function)\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m isnested(func\u001b[38;5;241m=\u001b[39mtask_function)\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_functools_wrapped_module_level(task_function)\n\u001b[1;32m    137\u001b[0m     ):\n",
      "File \u001b[0;32m~/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages/flytekit/core/python_auto_container.py:85\u001b[0m, in \u001b[0;36mPythonAutoContainerTask.__init__\u001b[0;34m(self, name, task_config, task_type, container_image, requests, limits, environment, task_resolver, secret_requests, pod_template, pod_template_name, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m TaskMetadata()\n\u001b[1;32m     83\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mpod_template_name \u001b[38;5;241m=\u001b[39m pod_template_name\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43msecurity_ctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msec_ctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_image \u001b[38;5;241m=\u001b[39m container_image\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# TODO(katrogan): Implement resource overrides\u001b[39;00m\n",
      "File \u001b[0;32m~/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages/flytekit/core/base_task.py:420\u001b[0m, in \u001b[0;36mPythonTask.__init__\u001b[0;34m(self, task_type, name, task_config, interface, environment, disable_deck, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    396\u001b[0m     task_type: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    403\u001b[0m ):\n\u001b[1;32m    404\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;124;03m        task_type (str): defines a unique task-type for every new extension. If a backend plugin is required then\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;124;03m        disable_deck (bool): If true, this task will not output deck html file\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    418\u001b[0m         task_type\u001b[38;5;241m=\u001b[39mtask_type,\n\u001b[1;32m    419\u001b[0m         name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m--> 420\u001b[0m         interface\u001b[38;5;241m=\u001b[39m\u001b[43mtransform_interface_to_typed_interface\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterface\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    421\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    422\u001b[0m     )\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_interface \u001b[38;5;241m=\u001b[39m interface \u001b[38;5;28;01mif\u001b[39;00m interface \u001b[38;5;28;01melse\u001b[39;00m Interface()\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_environment \u001b[38;5;241m=\u001b[39m environment \u001b[38;5;28;01mif\u001b[39;00m environment \u001b[38;5;28;01melse\u001b[39;00m {}\n",
      "File \u001b[0;32m~/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages/flytekit/core/interface.py:247\u001b[0m, in \u001b[0;36mtransform_interface_to_typed_interface\u001b[0;34m(interface)\u001b[0m\n\u001b[1;32m    242\u001b[0m     input_descriptions \u001b[38;5;241m=\u001b[39m interface\u001b[38;5;241m.\u001b[39mdocstring\u001b[38;5;241m.\u001b[39minput_descriptions\n\u001b[1;32m    243\u001b[0m     output_descriptions \u001b[38;5;241m=\u001b[39m remap_shared_output_descriptions(\n\u001b[1;32m    244\u001b[0m         interface\u001b[38;5;241m.\u001b[39mdocstring\u001b[38;5;241m.\u001b[39moutput_descriptions, interface\u001b[38;5;241m.\u001b[39moutputs\n\u001b[1;32m    245\u001b[0m     )\n\u001b[0;32m--> 247\u001b[0m inputs_map \u001b[38;5;241m=\u001b[39m \u001b[43mtransform_variable_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_descriptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m outputs_map \u001b[38;5;241m=\u001b[39m transform_variable_map(interface\u001b[38;5;241m.\u001b[39moutputs, output_descriptions)\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _interface_models\u001b[38;5;241m.\u001b[39mTypedInterface(inputs_map, outputs_map)\n",
      "File \u001b[0;32m~/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages/flytekit/core/interface.py:345\u001b[0m, in \u001b[0;36mtransform_variable_map\u001b[0;34m(variable_map, descriptions)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m variable_map:\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m variable_map\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 345\u001b[0m         res[k] \u001b[38;5;241m=\u001b[39m \u001b[43mtransform_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescriptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages/flytekit/core/interface.py:350\u001b[0m, in \u001b[0;36mtransform_type\u001b[0;34m(x, description)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform_type\u001b[39m(x: \u001b[38;5;28mtype\u001b[39m, description: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _interface_models\u001b[38;5;241m.\u001b[39mVariable:\n\u001b[0;32m--> 350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _interface_models\u001b[38;5;241m.\u001b[39mVariable(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[43mTypeEngine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_literal_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, description\u001b[38;5;241m=\u001b[39mdescription)\n",
      "File \u001b[0;32m~/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages/flytekit/core/type_engine.py:827\u001b[0m, in \u001b[0;36mTypeEngine.to_literal_type\u001b[0;34m(cls, python_type)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;124;03mConverts a python type into a flyte specific ``LiteralType``\u001b[39;00m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    826\u001b[0m transformer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_transformer(python_type)\n\u001b[0;32m--> 827\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_literal_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpython_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    828\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_annotated(python_type):\n",
      "File \u001b[0;32m~/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages/flytekit/core/type_engine.py:320\u001b[0m, in \u001b[0;36mDataclassTransformer.get_literal_type\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFlytekit does not currently have support for FlyteAnnotations applied to Dataclass.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    316\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be parsed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    317\u001b[0m     )\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(t, DataClassJsonMixin):\n\u001b[0;32m--> 320\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataclass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should be decorated with @dataclass_json to be \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialized correctly\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[1;32m    323\u001b[0m schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mAssertionError\u001b[0m: Dataclass <class '__main__.reconstructionDatasetFile'> should be decorated with @dataclass_json to be serialized correctly"
     ]
    }
   ],
   "source": [
    "from flytekit import workflow, task, dynamic, kwtypes\n",
    "from bacalhau_apiclient.models import Spec, JobSpecDocker, publisher_spec\n",
    "from flytekitplugins.bacalhau import BacalhauTask\n",
    "from subprocess import check_call\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from lighthouseweb3 import Lighthouse\n",
    "bacalhau_reconstruction_job = BacalhauTask(\n",
    "    name='running surface_reconstruction_job',\n",
    "    inputs=kwtypes(\n",
    "        spec=dict,\n",
    "        api_version=str\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "store_result = BacalhauTask(\n",
    "    name='store_ipfs_result',\n",
    "    inputs=kwtypes(\n",
    "        spec=dict,\n",
    "        api_version=str\n",
    "    ),\n",
    ")\n",
    "\n",
    "@dataclass\n",
    "class reconstructionDatasetFile():\n",
    "    def __init__(self, toy_example, group, filename, scene_type):\n",
    "        self.group = group\n",
    "        self.filename = filename\n",
    "        self.scene_type = scene_type\n",
    "\n",
    "@task\n",
    "def surface_reconstruction_job(input_params_job: reconstructionDatasetFile) -> str:\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        task_1 = bacalhau_reconstruction_job(\n",
    "            api_version = \"v0.1\",\n",
    "            spec = dict(\n",
    "                engine=\"Docker\",\n",
    "                verifier=\"Noop\",\n",
    "                publisher_spec= {\"type\": \"IPFS\"},\n",
    "                docker= JobSpecDocker(\n",
    "                    image=\"devextralabs/neuralangelo:0.1\",\n",
    "                    entrypoint=[input_params_job.filename, input_params_job.scene_type, input_params_job.group],\n",
    "                ),\n",
    "                language= {\n",
    "                    \"job_context\": None,\n",
    "                },\n",
    "                wasm=None,\n",
    "                resources=None,\n",
    "                outputs=[\n",
    "                    {\n",
    "                        \"storage_source\": \"IPFS\",\n",
    "                        \"name\": \"outputs\",\n",
    "                        \"path\": \"/outputs\",\n",
    "                    }\n",
    "                ],\n",
    "                deal={\"concurrrrency\":1},\n",
    "            )\n",
    "        )   \n",
    "    except Exception as e:\n",
    "        print(\"under the surface_reconstruction_job task, the error is: \", e)\n",
    "\n",
    "    \n",
    "    cid = task_1\n",
    "    path = Path(os.path.join(os.getcwd(), \"/ipfs/\", cid))\n",
    "    lh = Lighthouse(token=os.environ.get(\"WEB3STORAGE_TOKEN\"))\n",
    "    print(\"uploading the file to the ipfs storage\")\n",
    "    print(lh.upload(path))    \n",
    "    ## here we use the lighthouse storage sdk , but for the web3storage we can also integrate following the tutorials as defined here: https://web3.storage/docs/quickstart/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now comes the stage for onchain disbursement of rewards:\n",
    "- we will be deploying and issuing reward token to the users based on the amount of stake that is provided to the other participants.\n",
    "- once we get the CID of the rendered dataset, then the token holders can select the amount of the tokens they can stake to the given dataset\n",
    "\n",
    "here we will be using the packages that are already deployed by the other packages.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting eth-brownie\n",
      "  Downloading eth_brownie-1.20.0-py3-none-any.whl (218 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.7/218.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: eth-rlp==1.0.1 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (1.0.1)\n",
      "Collecting pytest==6.2.5\n",
      "  Downloading pytest-6.2.5-py3-none-any.whl (280 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.7/280.7 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wcwidth==0.2.13 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (0.2.13)\n",
      "Collecting vvm==0.1.0\n",
      "  Downloading vvm-0.1.0-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: websockets==12.0 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (12.0)\n",
      "Collecting web3==6.15.0\n",
      "  Downloading web3-6.15.0-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: rpds-py==0.17.1 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (0.17.1)\n",
      "Requirement already satisfied: pyyaml==6.0.1 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (6.0.1)\n",
      "Requirement already satisfied: lru-dict==1.2.0 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (1.2.0)\n",
      "Collecting pygments==2.17.2\n",
      "  Using cached pygments-2.17.2-py3-none-any.whl (1.2 MB)\n",
      "Requirement already satisfied: attrs==23.2.0 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (23.2.0)\n",
      "Requirement already satisfied: eip712==0.2.4 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (0.2.4)\n",
      "Requirement already satisfied: importlib-metadata==7.0.1 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (7.0.1)\n",
      "Requirement already satisfied: pycryptodome==3.20.0 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (3.20.0)\n",
      "Collecting multidict==6.0.5\n",
      "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting eth-event==1.2.5\n",
      "  Downloading eth_event-1.2.5-py3-none-any.whl (7.5 kB)\n",
      "Requirement already satisfied: iniconfig==2.0.0 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (2.0.0)\n",
      "Requirement already satisfied: packaging==23.2 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (23.2)\n",
      "Requirement already satisfied: async-timeout==4.0.3 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (4.0.3)\n",
      "Collecting lazy-object-proxy==1.10.0\n",
      "  Downloading lazy_object_proxy-1.10.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (68 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.3/68.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cbor2==5.6.1\n",
      "  Downloading cbor2-5.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.0/242.0 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting hypothesis==6.27.3\n",
      "  Downloading hypothesis-6.27.3-py3-none-any.whl (384 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.6/384.6 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click==8.1.7 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (8.1.7)\n",
      "Collecting py-solc-x==1.1.1\n",
      "  Downloading py_solc_x-1.1.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: prompt-toolkit==3.0.43 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (3.0.43)\n",
      "Collecting certifi==2023.11.17\n",
      "  Using cached certifi-2023.11.17-py3-none-any.whl (162 kB)\n",
      "Requirement already satisfied: wheel==0.42.0 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (0.42.0)\n",
      "Requirement already satisfied: regex==2023.12.25 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (2023.12.25)\n",
      "Requirement already satisfied: bitarray==2.9.2 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (2.9.2)\n",
      "Requirement already satisfied: jsonschema==4.21.1 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (4.21.1)\n",
      "Collecting pytest-forked==1.6.0\n",
      "  Downloading pytest_forked-1.6.0-py3-none-any.whl (4.9 kB)\n",
      "Requirement already satisfied: semantic-version==2.10.0 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (2.10.0)\n",
      "Requirement already satisfied: wrapt==1.16.0 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (1.16.0)\n",
      "Requirement already satisfied: eth-account==0.10.0 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (0.10.0)\n",
      "Requirement already satisfied: eth-utils==2.3.1 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (2.3.1)\n",
      "Requirement already satisfied: eth-typing==3.5.2 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (3.5.2)\n",
      "Requirement already satisfied: jsonschema-specifications==2023.12.1 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (2023.12.1)\n",
      "Collecting pygments-lexer-solidity==0.7.0\n",
      "  Downloading pygments-lexer-solidity-0.7.0.tar.gz (7.3 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: urllib3==2.2.0 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (2.2.0)\n",
      "Requirement already satisfied: pyunormalize==15.1.0 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (15.1.0)\n",
      "Requirement already satisfied: charset-normalizer==3.3.2 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (3.3.2)\n",
      "Requirement already satisfied: hexbytes==0.3.1 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (0.3.1)\n",
      "Collecting py==1.11.0\n",
      "  Using cached py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
      "Requirement already satisfied: tqdm==4.66.1 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (4.66.1)\n",
      "Requirement already satisfied: pathspec==0.12.1 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (0.12.1)\n",
      "Requirement already satisfied: aiohttp==3.9.3 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (3.9.3)\n",
      "Collecting rlp==4.0.0\n",
      "  Using cached rlp-4.0.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: parsimonious==0.9.0 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (0.9.0)\n",
      "Requirement already satisfied: eth-keyfile==0.7.0 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (0.7.0)\n",
      "Requirement already satisfied: protobuf==4.25.2 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (4.25.2)\n",
      "Requirement already satisfied: toml==0.10.2 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (0.10.2)\n",
      "Requirement already satisfied: sortedcontainers==2.4.0 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (2.4.0)\n",
      "Requirement already satisfied: idna==3.6 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (3.6)\n",
      "Requirement already satisfied: mypy-extensions==1.0.0 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (1.0.0)\n",
      "Requirement already satisfied: tomli==2.0.1 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (2.0.1)\n",
      "Collecting pytest-xdist==1.34.0\n",
      "  Downloading pytest_xdist-1.34.0-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: six==1.16.0 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (1.16.0)\n",
      "Collecting platformdirs==4.2.0\n",
      "  Downloading platformdirs-4.2.0-py3-none-any.whl (17 kB)\n",
      "Collecting python-dotenv==0.16.0\n",
      "  Downloading python_dotenv-0.16.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting black==24.1.1\n",
      "  Downloading black-24.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pluggy==1.4.0 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (1.4.0)\n",
      "Requirement already satisfied: toolz==0.12.1 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (0.12.1)\n",
      "Collecting eth-abi==5.0.0\n",
      "  Downloading eth_abi-5.0.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: eth-hash[pycryptodome]==0.6.0 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (0.6.0)\n",
      "Requirement already satisfied: referencing==0.33.0 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (0.33.0)\n",
      "Collecting eth-keys==0.5.0\n",
      "  Using cached eth_keys-0.5.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: cytoolz==0.12.3 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (0.12.3)\n",
      "Requirement already satisfied: asttokens==2.4.1 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (2.4.1)\n",
      "Requirement already satisfied: typing-extensions==4.9.0 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (4.9.0)\n",
      "Requirement already satisfied: requests==2.31.0 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (2.31.0)\n",
      "Requirement already satisfied: zipp==3.17.0 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (3.17.0)\n",
      "Requirement already satisfied: psutil==5.9.8 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (5.9.8)\n",
      "Collecting py-solc-ast==1.2.10\n",
      "  Downloading py_solc_ast-1.2.10-py3-none-any.whl (10.0 kB)\n",
      "Collecting execnet==2.0.2\n",
      "  Downloading execnet-2.0.2-py3-none-any.whl (37 kB)\n",
      "Collecting vyper==0.3.10\n",
      "  Downloading vyper-0.3.10-py3-none-any.whl (262 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.3/262.3 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: yarl==1.9.4 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (1.9.4)\n",
      "Requirement already satisfied: frozenlist==1.4.1 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (1.4.1)\n",
      "Requirement already satisfied: aiosignal==1.3.1 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (1.3.1)\n",
      "Requirement already satisfied: dataclassy==0.11.1 in /home/ubuntu/app/version-2-geospatial-pipelines/geospatial-pipelines/packages/flyte/.venv/lib/python3.10/site-packages (from eth-brownie) (0.11.1)\n",
      "Building wheels for collected packages: pygments-lexer-solidity\n",
      "  Building wheel for pygments-lexer-solidity (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pygments-lexer-solidity: filename=pygments_lexer_solidity-0.7.0-py3-none-any.whl size=7295 sha256=4e9f978ee142ffcd24061c58c3f13946f818da9b87dca488f4fed337df9f4410\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/ab/2d/d2/4203f3171dbe5a2c79e73c10f0420a8d84a92dafe429640eb2\n",
      "Successfully built pygments-lexer-solidity\n",
      "Installing collected packages: python-dotenv, pygments, py-solc-ast, py, platformdirs, multidict, lazy-object-proxy, hypothesis, execnet, certifi, cbor2, vyper, pytest, pygments-lexer-solidity, black, vvm, rlp, pytest-forked, py-solc-x, eth-keys, eth-abi, pytest-xdist, eth-event, web3, eth-brownie\n",
      "  Attempting uninstall: python-dotenv\n",
      "    Found existing installation: python-dotenv 1.0.1\n",
      "    Uninstalling python-dotenv-1.0.1:\n",
      "      Successfully uninstalled python-dotenv-1.0.1\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.15.0\n",
      "    Uninstalling Pygments-2.15.0:\n",
      "      Successfully uninstalled Pygments-2.15.0\n",
      "  Attempting uninstall: platformdirs\n",
      "    Found existing installation: platformdirs 4.1.0\n",
      "    Uninstalling platformdirs-4.1.0:\n",
      "      Successfully uninstalled platformdirs-4.1.0\n",
      "  Attempting uninstall: multidict\n",
      "    Found existing installation: multidict 6.0.4\n",
      "    Uninstalling multidict-6.0.4:\n",
      "      Successfully uninstalled multidict-6.0.4\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2023.7.22\n",
      "    Uninstalling certifi-2023.7.22:\n",
      "      Successfully uninstalled certifi-2023.7.22\n",
      "  Attempting uninstall: pytest\n",
      "    Found existing installation: pytest 7.4.4\n",
      "    Uninstalling pytest-7.4.4:\n",
      "      Successfully uninstalled pytest-7.4.4\n",
      "  Attempting uninstall: black\n",
      "    Found existing installation: black 22.12.0\n",
      "    Uninstalling black-22.12.0:\n",
      "      Successfully uninstalled black-22.12.0\n",
      "  Attempting uninstall: rlp\n",
      "    Found existing installation: rlp 3.0.0\n",
      "    Uninstalling rlp-3.0.0:\n",
      "      Successfully uninstalled rlp-3.0.0\n",
      "  Attempting uninstall: eth-keys\n",
      "    Found existing installation: eth-keys 0.4.0\n",
      "    Uninstalling eth-keys-0.4.0:\n",
      "      Successfully uninstalled eth-keys-0.4.0\n",
      "  Attempting uninstall: eth-abi\n",
      "    Found existing installation: eth-abi 4.2.1\n",
      "    Uninstalling eth-abi-4.2.1:\n",
      "      Successfully uninstalled eth-abi-4.2.1\n",
      "  Attempting uninstall: web3\n",
      "    Found existing installation: web3 6.15.1\n",
      "    Uninstalling web3-6.15.1:\n",
      "      Successfully uninstalled web3-6.15.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pydantic-settings 2.1.0 requires python-dotenv>=0.21.0, but you have python-dotenv 0.16.0 which is incompatible.\n",
      "py-evm 0.7.0a4 requires eth-keys<0.5.0,>=0.4.0, but you have eth-keys 0.5.0 which is incompatible.\n",
      "py-evm 0.7.0a4 requires rlp<4,>=3, but you have rlp 4.0.0 which is incompatible.\n",
      "nerfstudio 1.0.1 requires protobuf!=3.20.0,<=3.20.3, but you have protobuf 4.25.2 which is incompatible.\n",
      "flytekit 1.8.1 requires urllib3<2.0.0,>=1.22, but you have urllib3 2.2.0 which is incompatible.\n",
      "eth-tester 0.9.1b2 requires eth-keys<0.5.0,>=0.4.0, but you have eth-keys 0.5.0 which is incompatible.\n",
      "eth-tester 0.9.1b2 requires rlp<4,>=3.0.0, but you have rlp 4.0.0 which is incompatible.\n",
      "eth-ape 0.7.7 requires eth-abi<5,>=4.2.1, but you have eth-abi 5.0.0 which is incompatible.\n",
      "bacalhau-sdk 1.1.1 requires black<23.0.0,>=22.12.0, but you have black 24.1.1 which is incompatible.\n",
      "bacalhau-sdk 1.1.1 requires certifi==2023.07.22, but you have certifi 2023.11.17 which is incompatible.\n",
      "bacalhau-sdk 1.1.1 requires pygments==2.15.0, but you have pygments 2.17.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed black-24.1.1 cbor2-5.6.1 certifi-2023.11.17 eth-abi-5.0.0 eth-brownie-1.20.0 eth-event-1.2.5 eth-keys-0.5.0 execnet-2.0.2 hypothesis-6.27.3 lazy-object-proxy-1.10.0 multidict-6.0.5 platformdirs-4.2.0 py-1.11.0 py-solc-ast-1.2.10 py-solc-x-1.1.1 pygments-2.17.2 pygments-lexer-solidity-0.7.0 pytest-6.2.5 pytest-forked-1.6.0 pytest-xdist-1.34.0 python-dotenv-0.16.0 rlp-4.0.0 vvm-0.1.0 vyper-0.3.10 web3-6.15.0\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## first setting up the contracts folder from @geospatial-pipeline/web3 and then compiling the packages\n",
    "\n",
    "from brownie import accounts\n",
    "from subprocess import check_call\n",
    "\n",
    "\n",
    "## compiling the contracts \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
